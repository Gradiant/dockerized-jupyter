FROM alpine:3.8

LABEL maintainer="cgiraldo@gradiant.org" \
      organization="gradiant.org"

ENV JUPYTER_VERSION=5.7.4 \
    JUPYTERLAB_VERSION=0.35.4 \
    JUPYTER_PORT=8888 \
    JUPYTERLAB=false

##############################
# JUPYTER layers
##############################
RUN set -ex && \
    apk add --no-cache bash \
        build-base \
        python3 \
        python3-dev \
        zeromq-dev \
        libxml2-dev \
        libxslt-dev \
        # enable NOTEBOOK_URL to get git repos
        git && \
    pip3 install --upgrade pip && \
    pip3 install --no-cache-dir notebook==${JUPYTER_VERSION} jupyterlab==${JUPYTERLAB_VERSION} ipywidgets jupyter-contrib-nbextensions && \
    jupyter contrib nbextension install && \
    ## Fix nbextension tab disappearing https://github.com/Jupyter-contrib/jupyter_nbextensions_configurator/pull/85
    sed -i 's/jqueryui/jquery/g' /usr/lib/python3.6/site-packages/jupyter_nbextensions_configurator/static/nbextensions_configurator/tree_tab/main.js && \  
    mkdir /notebooks  && \
    wget https://github.com/jgm/pandoc/releases/download/2.6/pandoc-2.6-linux.tar.gz && \
    tar -xvzf pandoc-2.6-linux.tar.gz && \
    mv pandoc-2.6/bin/pandoc* /usr/local/bin/ && \
    rm -rf pandoc*


COPY files/jupyter/ /

VOLUME /notebooks

ENTRYPOINT ["/entrypoint.sh"]

##############################
# Spark & Kafka Support layers
##############################

ENV JAVA_HOME=/usr/lib/jvm/default-jvm/ \
    SPARK_VERSION=2.4.0 \
    SPARK_HOME=/opt/spark \
    PATH="$PATH:$SPARK_HOME/sbin:$SPARK_HOME/bin" \
    SPARK_URL="local[*]" \
# WARNING py4j version may change depending on SPARK_VERSION
    PYTHONPATH="$SPARK_HOME/python:$SPARK_HOME/python/build:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH" \
    SPARK_OPTS=""

RUN apk add --no-cache openjdk8-jre libc6-compat && mkdir /opt && \
    wget -qO- https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop2.7.tgz | tar xvz -C /opt && \
    ln -s /opt/spark-$SPARK_VERSION-bin-hadoop2.7 /opt/spark && \
    wget http://central.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.11/$SPARK_VERSION/spark-sql-kafka-0-10_2.11-$SPARK_VERSION.jar \
    -O /opt/spark-$SPARK_VERSION-bin-hadoop2.7/jars/spark-sql-kafka-0-10_2.11-$SPARK_VERSION.jar && \
    wget http://central.maven.org/maven2/org/apache/kafka/kafka-clients/1.0.0/kafka-clients-1.0.0.jar \
    -O /opt/spark-$SPARK_VERSION-bin-hadoop2.7/jars/kafka-clients-1.0.0.jar

##############################
# PYTHON Data-science layers
##############################
COPY files/python/py3-pandas-0.24.1-r0.apk / 
RUN set -ex && \
    apk add --no-cache \
        py3-numpy \
        py-numpy-dev \
        py3-scipy \
        py3-numpy-f2py \
        # matplotlib deps
        freetype-dev \
        libpng-dev \
        # enable NOTEBOOK_URL to get git repos
        git && \
    apk add --allow-untrusted /py3-pandas-0.24.1-r0.apk && rm /py3-pandas-0.24.1-r0.apk && \
    pip3 install --no-cache-dir pandasql scikit-learn matplotlib plotly ipyleaflet && \
    # findspark to use pyspark with regular ipython kernel. At the beggining of your notebook run
    # import findspark
    # findspark.init()
    # import pyspark
    pip3 install findspark

#############################
# BeakerX Extensions for scala kernel
#############################
RUN pip3 install beakerx requests && \
        cp -r /usr/lib/python3.6/site-packages/beakerx/static/* /usr/share/jupyter/nbextensions/beakerx/ && \
        beakerx install 
